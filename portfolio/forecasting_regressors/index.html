<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Forecasting with External Regressors</title>
<meta name="description" content="Code and Stuff">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="https://markleboeuf.github.io/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="https://markleboeuf.github.io/css/font-awesome.min.css">
<link rel="stylesheet" href="https://markleboeuf.github.io/css/owl.carousel.css">
<link rel="stylesheet" href="https://markleboeuf.github.io/css/owl.theme.css">


  <link href="https://markleboeuf.github.io/css/style.red.css" rel="stylesheet" id="theme-stylesheet">


<link href="https://markleboeuf.github.io/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="https://markleboeuf.github.io/img/favicon.png">


</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="/">Mark LeBoeuf</a></h1>
    
      <p class="sidebar-p">I am a Data Scientist currently based in Portland, OR.</p>
    
    <ul class="sidebar-menu">
      
      
        <li><a href="https://markleboeuf.github.io/">Home</a></li>
      
        <li><a href="https://markleboeuf.github.io/about/">About</a></li>
      
    </ul>
    <p class="social">
  
  
  
  
  
  
  <a href="https://www.linkedin.com/in/markleboeuf/" data-animate-hover="pulse">
    <i class="fa fa-linkedin"></i>
  </a>
  
  
  
  <a href="https://github.com/markleboeuf/markleboeuf.github.io" data-animate-hover="pulse">
    <i class="fa fa-github"></i>
  </a>
  
</p>


    <div class="copyright">
      <p class="credit">
        
          &copy;2016 Mark LeBoeuf
        
        | Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="/">Mark LeBoeuf</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Forecasting with External Regressors</h1>
         <p>This post focuses on some of my favorite things &ndash; data, sports, and forecasting &ndash; and will outline how to leverage external regressors when creating forecasts. We&rsquo;ll do some webscraping in R and Python to create our dataset, and then forecast how many people will visit Tom Brady&rsquo;s wikipedia page.
</p>

<p><img src="../forecasting_regressors_images/hey_tom.jpg" class="img-responsive" style="display: block; margin: auto;" /></p>

<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#collecting-month-level-traffic">Collecting Month Level Traffic</a></li>
<li><a href="#collecting-historical-game-data">Collecting Historical Game Data</a></li>
<li><a href="#model-selection-and-validation">Model Selection And Validation</a></li>
<li><a href="#seasonal-arimax-model">Seasonal ARIMAX Model</a></li>
</ul>

<h2 id="overview">Overview</h2>

<p>Imagine it&rsquo;s January 1st, 2015 and the New England Patriots have made the playoffs yet again. You run a webpage dedicated to Tom Brady and want to ensure you have enough servers ready to meet traffic to your website during the playoffs. Based on the past few years, you&rsquo;ve noticed that traffic during January and February increases when the patriots win playoff games. Thus you need a traffic forecast for these two months to determine how many people will visit your site.</p>

<p>Additionally, you want to quantify the effect of the number of playoff games won on monthly traffic. For example, what happens if the Patriots win two playoff games instead of one? Finally, you want an estimate of the probability of each of these scenarios unfolding&ndash;that is, the chances of winning 0, 1, 2, or all 3 playoff games. To achieve these objectives, we&rsquo;ll rely on the following sources of data:</p>

<ul>
<li>Month Level Internet Traffic</li>
<li>Historical Game Outcomes</li>
<li>Historical Betting Lines</li>
</ul>

<p>I&rsquo;ll go through the collection process associated with each and then we&rsquo;ll generate some forecasts!</p>

<h3 id="collecting-month-level-traffic">Collecting Month Level Traffic</h3>

<p>Let&rsquo;s start by loading the required libraries and setting our working directory.</p>

<pre><code class="language-r">libs = c('wikipediatrend', 'dplyr', 'data.table', 'rvest', 'forecast', 'artyfarty', 'knitr', 'ggplot2', 'forcats', 'lazyeval')
lapply(libs, require, character.only = TRUE)
wd = &quot;your_working_directory_here&quot;
setwd(wd)
</code></pre>

<p>Now we&rsquo;ll collect historical page views. This data comes from Wikipedia and will serve as the dependent variable in our forecast.</p>

<pre><code class="language-r">page_views_by_day &lt;- wp_trend(&quot;Tom Brady&quot;, from = &quot;2006-09-01&quot;,
                                           to = &quot;2015-03-01&quot;)

page_views_clean$date = as.Date(page_views_clean$date)

page_views_clean &lt;- page_views_by_day %&gt;%
                    dplyr::mutate(year = year(date),
                                  month = month(date),
                                  week = week(date)) %&gt;%
                    dplyr::rename(page_views = count) %&gt;%
                    dplyr::select(date, year, month, week, page_views)
</code></pre>

<p>Let&rsquo;s have a look at the first 5 rows</p>

<p><img src="../forecasting_regressors_images/table1.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<h3 id="collecting-historical-game-data">Collecting Historical Game Data</h3>

<p>Next we&rsquo;ll collect data on how the New England Patriots have historically performed during the playoffs, and then join this with our page views data set. I&rsquo;m using the <code>rvest</code> package to scrape the outcomes (win or lose) of the Patriots vs. each of the other 31 NFL teams.</p>

<pre><code class="language-r"> n_teams = 32
 team_name = &quot;new-england-patriots&quot;
 game_data = data.frame(NULL)
 
 for(team_number in as.character(seq(1, n_teams))){
   print(paste0(&quot;GATHERING DATA FOR TEAM: &quot;, team_number))
   url = paste0(&quot;http://www.footballdb.com/teams/nfl/&quot;,
                team_name,
                &quot;/teamvsteam?opp=&quot;,
                team_number)
   historical_record = url %&gt;% 
     read_html() %&gt;% 
     html_nodes(xpath = '//*[@id=&quot;leftcol&quot;]/div[9]/table') %&gt;% 
     html_table(fill = TRUE, header = TRUE) %&gt;% 
     as.data.frame()
   game_data = rbind(game_data, historical_record) 
}

game_data_clean = game_data %&gt;% 
                  dplyr::rename(date = Date) %&gt;%
                  dplyr::mutate(new_date = substring(date, 1, 10)) %&gt;% 
                  dplyr::mutate(new_date = as.Date(new_date, 
                                format = &quot;%m/%d/%Y&quot;)) %&gt;% 
                  dplyr::arrange(desc(new_date)) %&gt;% 
                  dplyr::select(date, new_date, Result)
</code></pre>

<p>Again let&rsquo;s see what our data looks like:</p>

<p><img src="../forecasting_regressors_images/table2b.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Overall looks pretty good but we still have some cleaning to do. What we want here are the dates of the playoff games and their outcomes. Luckily there is an asterik delineating regular season games from playoff games, and we&rsquo;ll use this symbol to identify the playoff games.</p>

<pre><code class="language-r">game_data_outcome = game_data_clean %&gt;% 
                    dplyr::mutate(date_length = nchar(
                                                as.character(date))
                                  ) %&gt;% 
                    dplyr::mutate(playoff_game = ifelse(date_length == 20, 1, 0),
                    result = substring(Result, 1, 1)) %&gt;% 
                    dplyr::mutate(result = ifelse(result == &quot;W&quot;, 1, 0)) %&gt;% 
                    dplyr::select(new_date, playoff_game, result) %&gt;% 
                    dplyr::rename(date = new_date) 

</code></pre>

<p><img src="../forecasting_regressors_images/table2a.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Now we are ready to combine our game data with our traffic data.</p>

<pre><code class="language-r">joined_df = dplyr::left_join(page_views_clean, game_data_outcome) %&gt;% 
            dplyr::mutate(playoff_game = ifelse(is.na(playoff_game) == TRUE | 
            playoff_game == 0, 0, 1)) %&gt;% 
            dplyr::filter(year &gt; 2007 &amp; year &lt; 2016)

playoff_wins = joined_df %&gt;% 
               dplyr::filter(playoff_game == 1) %&gt;% 
               dplyr::group_by(year) %&gt;% 
               dplyr::summarise(playoff_games_won = sum(result))

playoff_games = joined_df %&gt;% 
                dplyr::group_by(year) %&gt;% 
                dplyr::summarise(playoff_games_played = 
                                 sum(playoff_game)) %&gt;% 
                dplyr::left_join(playoff_wins) %&gt;% 
                data.frame() %&gt;% 
                dplyr::mutate(playoff_games_won = ifelse(is.na(
                                                          playoff_games_won) == TRUE, 0, 
                                                                    playoff_games_won))
joined_df_game = joined_df %&gt;% 
                 dplyr::inner_join(playoff_games) %&gt;% 
                 dplyr::group_by(year, month, 
                                 playoff_games_played, 
                                 playoff_games_won) %&gt;% 
                 dplyr::mutate(month_max_date = max(date)) %&gt;% 
                 dplyr::group_by(year, month, playoff_games_played, 
                                 playoff_games_won, month_max_date) %&gt;% 
                 dplyr::summarise(monthly_page_views = sum(page_views)) %&gt;% 
                 data.frame()

joined_df_game$playoff_games_played = ifelse(joined_df_game$month %in% c(1, 2), 
joined_df_game$playoff_games_played, 0)

joined_df_game$playoff_games_won = ifelse(joined_df_game$month %in% c(1, 2), 
joined_df_game$playoff_games_won, 0)
</code></pre>

<p>And we&rsquo;ll have a look at the first 5 rows:</p>

<p><img src="../forecasting_regressors_images/table4.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<h3 id="visualizing-wins-vs-traffic">Visualizing Wins vs. Traffic</h3>

<p>Now that we have our analytical dataset, let&rsquo;s visualize the relationship between playoff games and page views during Jan/Feb.</p>

<pre><code class="language-r">my_plot_theme = function(){
                font_family = &quot;Helvetica&quot;
                font_face = &quot;bold&quot;

                return(theme(
                       axis.text.x = element_text(size = 18, 
                                                  face = font_face, 
                                                  family = font_family),
                       axis.text.y = element_text(size = 18, 
                                                  face = font_face, 
                                                  family = font_family),
                       axis.title.x = element_text(size = 20, 
                                                   face = font_face, 
                                                    family = font_family),
                       axis.title.y = element_text(size = 20, face = font_face, family = font_family),
                       strip.text.y = element_text(size = 18, face = font_face, family = font_family),
                       plot.title = element_text(size = 24, face = font_face, family = font_family),
                       legend.position = &quot;top&quot;,
                       legend.title = element_text(colour = &quot;white&quot;, size = 16,
                       face = font_face,
                       family = font_family),
                       legend.text = element_text(colour = &quot;white&quot;, size = 14,
                       face = font_face,
                       family = font_family)))
}
monokai_values = c(&quot;#F92672&quot;, &quot;#66D9EF&quot;, &quot;#A6E22E&quot;, &quot;#FD971F&quot;)
monokai_line_color = &quot;#A59F85&quot;

train_test_df &lt;- joined_df_game %&gt;% 
                 dplyr::filter(month_max_date &lt;= '2015-02-28') %&gt;% 
                 dplyr::mutate(train_test_flag = ifelse(year &gt; 2014, &quot;test&quot;, &quot;train&quot;))
                               playoff_dates = train_test_df %&gt;% 
                 dplyr::filter(month %in% c(1, 2)) %&gt;% 
                 dplyr::select(month_max_date)


train_df_final = train_test_df %&gt;% 
                 dplyr::filter(train_test_flag == 'train') %&gt;% 
                 dplyr::select(year, month, month_max_date, 
                               playoff_games_won, monthly_page_views)

ggplot(train_df_final, aes(x = month_max_date, y = monthly_page_views/1e3)) + 
    geom_line(size = 1, color = monokai_line_color) +
    geom_point(aes(color = as.factor(playoff_games_won)), size = 4) + 
    theme_monokai_full() + 
    scale_color_manual(values = monokai_values[1:3],
    guide = guide_legend(title = &quot;Playoff Games Won&quot;)) + 
    my_plot_theme() + 
    xlab(&quot;Date&quot;) + ylab(&quot;Monthly Page Views (K)&quot;)
</code></pre>

<p><img src="../forecasting_regressors_images/playoff_games_won.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>The above plot suggests that playoff games/wins do relate to page views. Now we&rsquo;ll do some validation work to see if including this information as an external regressor actually improves our forecasts.</p>

<h3 id="model-selection-and-validation">Model Selection and Validation</h3>

<p>Since the period we want to forecast is Jan/Feb 2015, we&rsquo;ll hold out the two months of traffic results from Jan/Feb 2014 as a way to identify which inputs will likely yield the most accurate forecasts. We will specify an ARIMA model with a single external regressor (games won and games played), and compare the results on our validation set against an ARIMA model that relies on history alone.</p>

<pre><code class="language-r"># filter data until last year and create training and validation time periods

train_validation = joined_df_game %&gt;% 
                   dplyr::filter(month_max_date &lt;= &quot;2014-02-28&quot;) %&gt;% 
                   dplyr::mutate(train_test_flag = ifelse(year &lt; 2014, 
                                               &quot;train&quot;, &quot;validation&quot;))

training_df = train_validation %&gt;% 
              dplyr::filter(train_test_flag == 'train')

validation_df = train_validation %&gt;% 
                dplyr::filter(train_test_flag == 'validation')

# create our time-series object 
page_views_ts = ts(training_df$monthly_page_views, 
                frequency = 12,
                start = c(head(training_df, 1)$year, 
                          head(training_df, 1)$month),
                end = c(tail(training_df, 1)$year, 
                        tail(training_df, 1)$month))

# specify that we want to make a forecast 2 periods ahead
prediction_horizon = 2

# arima model with no external regressors
arima_no_xreg = auto.arima(page_views_ts)
arima_no_xreg_f =  data.frame(forecast(arima_no_xreg, h = prediction_horizon))

#arima model with playoff games played as an external regessor
arima_games_played = auto.arima(page_views_ts, xreg = training_df$playoff_games_played)
arima_games_played_f = data.frame(forecast(arima_games_played, h = prediction_horizon,
                                  xreg = validation_df$playoff_games_played))

#arima model with playoff games won as an external regessor
arima_games_won = auto.arima(page_views_ts, xreg = training_df$playoff_games_won)
arima_games_won_f = data.frame(forecast(arima_games_won, 
                               h = prediction_horizon,
                               xreg = validation_df$playoff_games_won))
#
forecast_df = rbind(arima_no_xreg_f, arima_games_played_f, arima_games_won_f) %&gt;% 
              dplyr::rename(predicted_monthly_views = Point.Forecast) %&gt;% 
              dplyr::mutate(forecast_model =
                           c(rep('No.Xreg', 2), 
                           rep('Games.Played', 2),
                           rep('Games.Won',2)),
                           actual_monthly_views = rep(validation_df$monthly_page_views, 3)) %&gt;% 
              dplyr::select(forecast_model, predicted_monthly_views, actual_monthly_views)
</code></pre>

<p><img src="../forecasting_regressors_images/table4b.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Now we can compare our predictions against what actually happened. There are a variety of ways to measure error in forecasting, and in this case we&rsquo;ll use the Mean Average Percent Error (MAPE), which is calculated as follows:</p>

<p><img src="../forecasting_regressors_images/mape_equation.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Where e<sub>t</sub> is the difference between the predicted and actual and y<sub>t</sub> is our actual. As with all error metrics, there are pros and cons to quantifying error with MAPE. The main advantage is ease of interpretation. Telling someone &ldquo;our forecasts were off by 50%&rdquo; is easier than saying &ldquo;our forecasts were off by 10,458 units&rdquo;. The main disadvantage is that the scale on which your calculating your error matters. For example, a 10% miss on 10 units (1) is a lot smaller than a 10% MAPE on 100,000 units (10K) yet they are treated equally. Additionally, having a small value in the denominator can make a forecast look much worse than it actually is. Therefore, if you are working with small quantities, I&rsquo;d advise using a different error metric. The quantities in this example are far from zero, so MAPE serves as a simple way to convey forecasting error. Let&rsquo;s compare our MAPEs between the different forecasting inputs.</p>

<pre><code class="language-r">calcMape = function(predicted_amt, actual_amt){
                    return(round(mean(abs(predicted_amt - actual_amt)/actual_amt) * 100, 1))
}

validation_output = forecast_df %&gt;% 
                    dplyr::group_by(forecast_model) %&gt;% 
                    dplyr::do(mape = calcMape(.$predicted_monthly_views,
                                              .$actual_monthly_views)) %&gt;% 
                    data.frame() %&gt;% 
                    dplyr::mutate(mape = unlist(mape),
                                  forecast_model = factor(forecast_model)) %&gt;% 
                    dplyr::mutate(forecast_model = fct_reorder(forecast_model, mape, .desc = FALSE))

</code></pre>

<pre><code class="language-r">ggplot(validation_output, aes(x = forecast_model, y = round(mape, 0),
        fill = forecast_model, label = as.character(round(mape, 0)))) + 
        geom_bar(stat = &quot;identity&quot;) + 
        theme_monokai_full() + 
        my_plot_theme() + # see end of post for my_plot_theme() function
        scale_fill_manual(values = monokai_values[1:nrow(validation_output)]) + 
        xlab(&quot;Forecasting Inputs&quot;) + ylab(&quot;MAPE&quot;) + 
        theme(legend.position = &quot;none&quot;) + 
        geom_label(label.size = 1, size = 10, color = &quot;white&quot;)

</code></pre>

<p><img src="../forecasting_regressors_images/mape_plot.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Based on the results from our validation set, the model that uses <em>Games Won</em> as an external regressor performed the best with a less than stellar 114 percent MAPE. We could reformulate our external regressor, try a different forecasting approach, or bring in additional covariates to improve our MAPE, but we&rsquo;ll keep it simple and just consider the aforementioned approaches.</p>

<p>So we figured out which input works best, and we have all of the data we need to make a traffic forecast. There&rsquo;s only one problem: We won&rsquo;t know how many games the Patriots are going to win during the playoffs. Thus we&rsquo;ll need t generate a prediction &ndash; 0, 1, 2, or 3 &ndash; for the expected number of games won as well, which will then serve as an input into our final, traffic-forecasting model.</p>

<h3 id="collecting-betting-lines">Collecting Betting Lines</h3>

<p>To help us make an informed decision about the number of games the Patriots will win during the playoffs, we can leverage historic NFL betting lines. If you aren&rsquo;t familiar with a betting lines, it&rsquo;s basically a way for odds-makers to encourage an equal number bets for both teams playing in a game.</p>

<p>Previously we used R to scrape data from the web. We&rsquo;ll switch over to Python for a little bit to gather the win probabilities associated with different betting lines. The <code>BeautifulSoup</code> module is awesome for doing webscraping, so that&rsquo;s what we&rsquo;ll use here.</p>

<pre><code class="language-python">import urllib2
from bs4 import BeautifulSoup
import re
import pandas as pd
import sys

opener = urllib2.build_opener()
opener.addheaders = [('User-Agent', 'Mozilla/5.0')]
temp_url = &quot;https://www.teamrankings.com/nfl/odds-history/results/&quot;
page = opener.open(temp_url)
page_soup = BeautifulSoup(page, 'html.parser')
table_data = page_soup.find_all(&quot;tr&quot;, {&quot;class&quot;: &quot;text-right nowrap&quot;})
spread = []
win_pct = []
for line in table_data:
    line_list = str(line).splitlines()
    try:
        spread.append(re.search('&lt;td&gt;(.*)&lt;/td&gt;', line_list[1]).group(1))
        win_pct.append(line_list[4].split(&quot;&gt;&quot;)[1].split(&quot;&lt;&quot;)[0])
    except:
        spread.append(None)
        win_pct.append(None)

historic_odds_df = pd.DataFrame({'spread': spread,
'win_pct': win_pct})

historic_odds_df.to_csv(sys.argv[1] + &quot;/historic_win_percentages.csv&quot;, index = False)
</code></pre>

<p>And here is how we can execute the spead_scrape.py script from R.</p>

<pre><code class="language-r">python_location = system(&quot;which python&quot;, intern = TRUE)

exe_py_command = paste0(python_location, &quot; &quot;, wd, &quot;/spread_scrape.py &quot;, wd)
</code></pre>

<p>If you aren&rsquo;t familiar with executing scripts in other languages from R (or the terminal), we can break this command down into further detail. It&rsquo;s quite simple. There are three components to above command:</p>

<ol>
<li>The location of the Python binaries on my machine &lsquo;//anaconda/bin/python&rsquo;.</li>
<li>The location of the Python script &lsquo;my_working_directory/spread_scrape.py&rsquo;</li>
<li>The location where I want the output to end up &lsquo;my_working_directory&rsquo;</li>
</ol>

<p>You&rsquo;ll also notice that in the last line of the Python script, theres a <code>sys.argv[1]</code>. That&rsquo;s basically says, &ldquo;I am going to execute this script from the command line, and I&rsquo;m going to pass in 1 argument (in this case the output directory).</p>

<p>Now let&rsquo;s actually do the scraping and see what we get back.</p>

<pre><code class="language-r"># Execute the python script from R
system(exe_py_command)

# Read the output back into R
historic_win_percent = data.table::fread(paste0(wd, &quot;/historic_win_percentages.csv&quot;),
                                         data.table = FALSE) 
</code></pre>

<p>Let&rsquo;s look at the first 20 observations.</p>

<p><img src="../forecasting_regressors_images/table5.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Perfect. The interpretation is really simple: A team favored by 12 points has historically won ~78% of their games; bump that spread up to 16 points and there has never been a team favored by 16 points that has lost. Let&rsquo;s see what that looks like starting at a zero-point spread, when both teams are perceived by odds-makers to be an equal match.</p>

<pre><code class="language-r">historic_win_percent_clean = historic_win_percent %&gt;% 
                             dplyr::filter(spread &lt;= 0) %&gt;% 
                             dplyr::mutate(win_pct = substring(win_pct, 1, 
                                                    (nchar(win_pct) - 1))) %&gt;% 
                             dplyr::mutate(win_pct = as.numeric(win_pct),
                                           spread = abs(spread)) %&gt;% 
                             dplyr::rename(favorite = spread)

ggplot(historic_win_percent_clean, aes(x = favorite, y = win_pct)) + 
    geom_point(alpha = 0) + 
    geom_line(alpha = 0) + 
    stat_smooth(span = 2.0, se = FALSE, size = 2, colour = monokai_line_color) + 
    ylim(50, 110) + 
    xlim(0, 27) + 
    scale_x_continuous(breaks = seq(0, 25, 5)) + 
    scale_y_continuous(breaks = seq(50, 110, 5)) + 
    theme_monokai_full() + 
    my_plot_theme() + 
    xlab(&quot;Point Favorite&quot;) + ylab(&quot;Chance of Winning&quot;) + 
    geom_vline(xintercept = 7, size = 2, colour = monokai_values[2]) + 
    geom_vline(xintercept = 5, size = 2, colour = monokai_values[3]) + 
    geom_vline(xintercept = 3, size = 2, colour = monokai_values[4]) + 
    annotate(&quot;rect&quot;, xmin = 18, xmax = 19, ymin = 88, ymax = 90, fill = monokai_values[2]) + 
    annotate(&quot;text&quot;, label = &quot;Game 1 Spread&quot;, x = 23, y = 89, size = 8, color = monokai_values[2]) + 
    annotate(&quot;rect&quot;, xmin = 18, xmax = 19, ymin = 85, ymax = 87, fill = monokai_values[3]) + 
    annotate(&quot;text&quot;, label = &quot;Game 2 Spread&quot;, x = 23, y = 86, size = 8, color = monokai_values[3]) + 
    annotate(&quot;rect&quot;, xmin = 18, xmax = 19, ymin = 82, ymax = 84, fill = monokai_values[4]) + 
    annotate(&quot;text&quot;, label = &quot;Game 3 Spread&quot;, x = 23, y = 83, size = 8, color = monokai_values[4])
</code></pre>

<p><img src="../forecasting_regressors_images/point_spread.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>We only know the spread for Game 1 because we are generating our forecasts at the beginning of January. The Patriots are favored by 7, and we know historically that when a team is favored by 7 they win about ~73% of the time. So I&rsquo;m feeling at least 1 win. What about 2? Here we are going to make an educated guess. We can assume that each subsequent game will be more challenging for the Patriots, so we&rsquo;ll make a prediction of a 5-point favorite. Finally, if the Patriots play in the Superbowl, let&rsquo;s predict they&rsquo;ll be a 3-point favorite. If we assume that the outcome of each playoff game is independent of the prior game (which, barring a major injury to a key player, is a reasonable assumption) we can calculate the probability of each of these scenarios unfolding:</p>

<p><img src="../forecasting_regressors_images/win_prob.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<h3 id="seasonal-arimax-model">Seasonal ARIMAX Model</h3>

<p>Now that we’ve trained our model let’s see what it looks like.</p>

<pre><code class="language-r">## Series: page_views_train_final 
## ARIMA(1,1,1)(0,1,1)[12]                    
## 
## Coefficients:
##          ar1      ma1     sma1  train_df_final$playoff_games_won
##       0.2673  -0.8559  -0.7373                         296550.82
## s.e.  0.1458   0.0723   0.2563                          36020.02
## 
## sigma^2 estimated as 1.28e+10:  log likelihood=-930.05
## AIC=1870.1   AICc=1871.02   BIC=1881.41
## 
## Training set error measures:
##                     ME     RMSE      MAE       MPE     MAPE      MASE
## Training set -22993.67 101058.3 61230.45 -26.36236 38.57438 0.6260494
##                     ACF1
## Training set -0.01938565
##                     ME     RMSE      MAE       MPE     MAPE      MASE
## Training set -22993.67 101058.3 61230.45 -26.36236 38.57438 0.6260494
##                     ACF1
## Training set -0.01938565
</code></pre>

<p>We haven&rsquo;t covered what&rsquo;s going on under the hood, so we&rsquo;ll go into detail on how to interpret the output. The great thing about the <code>auto.arima</code> function is that it does the hard work of identifying the best model specification from our training data. While this is a huge time-saver, it helps to understand how and why certain parameters were selected. If you happen to be a forecasting expert and just want to know how to implement the model, feel free to skip this next section.</p>

<p>Our model is <code>ARIMA(1,1,1)(0,1,1)[12]</code>. Let&rsquo;s focus on the first part  <code>ARIMA(1,1,1)</code></p>

<p>ARIMA stands for Auto-Regressive Integrated Moving Average, which is why it is abbreviated. Identifying the <strong>Integrated part</strong>  ARIMA(1, <strong>1</strong>, 1) is the first thing we do. It says &lsquo;this is how much you need to difference (Y~t - Y~t-1~) our time series by to make it stationary on the mean. Cool story Hansel. Now in English. Stationary implies that the average (or variance, or any other parameter) of our time series remains constant across time. If we have an upward or downward trend, our mean is not stationary (its changing!), so the model captures how much it is going up or down by each time step, and then subtracts that from each value so it remains flat (or stationary). Indeed, if a time series is stationary, it means that it&rsquo;s values do not depend on where we are in the time series.</p>

<p>Next the <strong>Auto-Regressive</strong> or (AR(1)) part. Auto-regressive roughly translates to &lsquo;regressed on itself&rsquo;, and implies that we can learn something about Y~t+1~ from Y~t~. Said differently, prior values (in this case from 1 prior time-step) are good indicators of subsequent future values, so we capture this with an auto-regressive term.</p>

<p>Finally the <strong>Moving Average</strong> or (MA(1)) part. Moving-average is similar to the A part, in that we use prior values to inform our prediction of future values, but instead of focusing on the actual values we focus instead on prior errors, specifically our forecasting errors. These errors are computed as we fit the model, and like many things in life, we use our past errors to inform our future predictions.</p>

<p>Now let&rsquo;s discuss the second part: <code>(0,1,1)[12]</code>. This is the seasonality portion of our model and can be interpreted similarly to the first part. The model is determining the difference in each month&rsquo;s number of views across time, so Jan. 2015 - Jan. 2014 - Jan 2013&hellip;you get the point. That&rsquo;s the integrated part. The model also calculates a historical moving average with exponential weighting. The amount of weighting (or smoothing) is determined by the <code>sma1</code> coefficient contained in the above model. Coefficients that are closer to 1 indicate that more months (across history) are being used to determine how much future months will differ from the average of previous months.</p>

<p>Finally the coefficient for our external regressor &ndash; number of post-season games won &ndash; has a value of 296550. This coefficient is interpreted just like a linear regression model; for each additional Patriot&rsquo;s post-season win, we expect ~296K more visits to Tom Brady&rsquo;s page.</p>

<p>If that all makes sense, let&rsquo;s test our model on the final data, with our external variable set to 2 playoff games, and see how our prediction of Tom Brady&rsquo;s page views compared to what actually happened. In essence, we are saying &ldquo;The Patriots will make the superbowl but wont win.&rdquo; It turns out betting against the Patriots in the superbowl can be a bad move, something I&rsquo;ve experienced firsthard.</p>

<pre><code class="language-r">test_df_final = train_test_df %&gt;% 
dplyr::filter(train_test_flag == 'test') %&gt;% 
dplyr::select(year, month, month_max_date, monthly_page_views)

test_df_prediction =  data.frame(forecast(arima_games_won_final,
xreg = c(2, 2),
h = 2))                    
test_df_final$predicted_monthly_views = test_df_prediction$Point.Forecast
print(test_df_final)
print(calcMape(test_df_final$predicted_monthly_views, test_df_final$monthly_page_views))
</code></pre>

<p>Our MAPE is about 35%, which is considerably better than the MAPE on our holdout set. However, our prediction of the Patriots only winning 2 games was wrong. The patriots won 3 post season games and beat the Seattle Seahawks 28-24 to win the superbowl. So what would&rsquo;ve happened if the value of our external regressor was correct (i.e., 3 instead of 2)? Or maybe we were too conservative and only predicted 1 win. How would each of these scenarios affected our forecasting accuracy? Let&rsquo;s find out.</p>

<pre><code class="language-r">what_if_df = data.frame(year = rep(test_df_final$year, 3),
                        month = rep(test_df_final$month, 3),
                        month_max_date = rep(test_df_final$month_max_date, 3),
                        playoff_games_won = rep(1:3, times=1, each=2)
                        )
forecast_vector = c()

for(games_played in unique(what_if_df$playoff_games_won)){
    temp_df = what_if_df %&gt;%
    dplyr::filter_(interp(paste0(&quot;playoff_games_won == &quot;, games_played)))
    temp_forecast = data.frame(forecast(arima_games_won_final,
                               xreg = temp_df$playoff_games_won,
                               h = prediction_horizon))
    forecast_vector = c(forecast_vector, temp_forecast$Point.Forecast)
}

what_if_df$forecasted_views = forecast_vector
what_if_df$actual_views = rep(test_df_final$monthly_page_views, 3)
</code></pre>

<pre><code class="language-r">what_if_df = what_if_df %&gt;% 
             dplyr::group_by(playoff_games_won) %&gt;%
             dplyr::do(mape = calcMape(.$forecasted_views, .$actual_views)) %&gt;%
             data.frame() %&gt;%
             dplyr::mutate(mape = unlist(mape),
                           playoff_games_won = factor(playoff_games_won)) %&gt;%
             dplyr::mutate(playoff_games_won = fct_reorder(playoff_games_won, 
                                                           mape, 
                                                           .desc = FALSE))
ggplot(what_if_df, aes(x = playoff_games_won, y = round(mape, 0),
                    fill = playoff_games_won, label = as.character(round(mape, 0)))) + 
        geom_bar(stat = &quot;identity&quot;) + 
        theme_monokai_full() + 
        my_plot_theme() + 
        scale_fill_manual(values = monokai_values[1:length(unique(what_if_df$playoff_games_won))]) + 
xlab(&quot;Value of Playoff Games Won&quot;) + ylab(&quot;MAPE&quot;) + 
theme(legend.position = &quot;none&quot;) + 
geom_label(label.size = 1, size = 10, color = &quot;white&quot;)

</code></pre>

<p><img src="../forecasting_regressors_images/mape_plot_final.png" class="img-responsive" style="display: block; margin: auto;" /></p>

<p>Hang on a second. So the model with the correct number of playoff games won (3) actually had the lowest accuracy? Yes and here&rsquo;s why: Across the history of our time series, the Patriots had never actually won 3 playoff games. They had only won 0, 1 or 2 games. Thus we are extrapolating to values not contained in our data set, which can be a recipe for disaster. If you look at the change in our forecast as we increase the number of playoff games won by 1 for the month of February, we expect an additional 296K visitors. We are making the assumption that there is a linear relationship between wins and page views, such that each additional win generates +296K views. This is clearly not the case, and the incorrect assumption is reflected in the accuracy of the resulting forecast.</p>

<p>Hopefully this post has eliminated some of the mystery around creating forecasts with external regressors.</p>
         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="https://markleboeuf.github.io/js/jquery.min.js"></script>
<script src="https://markleboeuf.github.io/js/bootstrap.min.js"></script>
<script src="https://markleboeuf.github.io/js/jquery.cookie.js"> </script>
<script src="https://markleboeuf.github.io/js/ekko-lightbox.js"></script>
<script src="https://markleboeuf.github.io/js/jquery.scrollTo.min.js"></script>
<script src="https://markleboeuf.github.io/js/masonry.pkgd.min.js"></script>
<script src="https://markleboeuf.github.io/js/imagesloaded.pkgd.min.js"></script>
<script src="https://markleboeuf.github.io/js/owl.carousel.min.js"></script>
<script src="https://markleboeuf.github.io/js/front.js"></script>

</body>
</html>
